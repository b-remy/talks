<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Likelihood free in Paris</title>

	<meta name="description" content="March 17th 2020">
	<link rel="stylesheet" href="reveal.js/dist/reset.css">
	<link rel="stylesheet" href="reveal.js/dist/reveal.css">
	<link rel="stylesheet" href="reveal.js/dist/theme/darkenergy.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css" id="highlight-theme">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section data-background-image="assets/lsst_stills_0009_crop.jpg">
				<div class="container">
					<div class="title" style="border-radius: 20px; background-color:rgba(0, 0, 0, 0.4);">
						<h1>Sampling high-dimensional posterior with a simulation based prior</h1>
					</div>
				</div>
				<!-- <hr> -->
				<div>
					<a href="https://arxiv.org/abs/2201.05561"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2201.05561-B31B1B.svg" class="plain" style="height:25px;" /></a>
					<a href="https://arxiv.org/abs/2011.08698"><img src="https://img.shields.io/badge/stat.ML-arXiv%3A2011.08698-B31B1B.svg" class="plain" style="height:25px;" /></a>
				</div>
				<div class="container">
					<div class="col">
						<div align="left" style="margin-left: 20px;">
							<h2>Benjamin Remy</h2>
							With : <u>Francois Lanusse</u>, Zaccharie Ramzi, Niall Jeffrey, Jia Liu, <u>J.-L. Starck</u>
							<img src="assets/CosmoStatDarkBK.png" class="plain"></img>
							<br>
						</div>
					</div>

					<div class="col">
						<br>
						<br>
						<br>
						<img src="assets/logo_cnes.png" class="plain" height="150"></img>
					</div>

					<div class="col">
						<br>
						<br>
						<img src="assets/universite_paris_saclay.jpg" class="plain" height="150"></img>
					</div>
				</div>
				<div style="border-radius: 20px; background-color:rgba(0, 0, 0, 0.4);"> slides at <a href="https://b-remy.github.io/talks/LFParis2022">b-remy.github.io/talks/LFParis2022</a> </div>

			</section>


			<section>
				<section>
					<h3 class="slide-title">Linear inverse problems</h3>

					$\boxed{y = \mathbf{A}x + n}$
					<br>
					<br>
					$\mathbf{A}$ is known and encodes our physical understanding of the problem.
					<span class="fragment"><br>$\Longrightarrow$ When non-invertible or ill-conditioned, the inverse problem is ill-posed <b class="alert">with no unique solution $x$</b></span>
					<div class="container fragment fade-up">
						<div class="col">
							<img data-src="assets/pluto_smooth.png" class="plain"></img>
							Deconvolution
						</div>
						<div class="col">
							<img data-src="assets/pluto_missing.png" class="plain"></img>
							Inpainting
						</div>
						<div class="col">
							<img data-src="assets/plutoNoise.png" class="plain"></img>
							Denoising
						</div>
					</div>
				</section>

				<section>
					<h3 class="slide-title">The Weak Lensing Mass-Mapping as an Inverse Problem</h3>
					<div class="container">
						<div class="col">
							Shear <b class="alert">$\gamma$</b><br>
							<img data-src="assets/shear_cat1.png" style="width:450px;"></img>
						</div>

						<div class="col fragment fade-up">
							Convergence <b class="alert">$\kappa$</b><br>
							<img data-src="assets/kappa.png" style="width:450px;"></img>
						</div>
					</div>

					<div style="position:relative; width:1000px; height:100px; margin:0 auto;">
						<div class="fragment current-visible plain fade-up" style="position:absolute;top:0;left:0;width:1000px;">
							$$\gamma_1 = \frac{1}{2} (\partial_1^2 - \partial_2^2) \ \Psi \quad;\quad \gamma_2 = \partial_1 \partial_2 \ \Psi \quad;\quad \kappa = \frac{1}{2} (\partial_1^2 + \partial_2^2) \ \Psi$$
						</div>
						<div class="fragment current-visible plain fade-up" style="position:absolute;top:0;left:0;width:1000px;">
							$$\boxed{\gamma = \mathbf{P} \kappa + n}$$
						</div>
					</div>
				</section>

				<section data-vertical-align-top>
					<h3 class="slide-title">Bayesian Modeling</h3>
					<div class="container">
						<div class="col-5" align="left">
							$$\boxed{\gamma = \mathbf{P}\kappa + n}$$
							$\mathbf{P}$ is known and encodes our physical understanding of the problem
							<span class="fragment fade-up"><br>$\Longrightarrow$ Non-invertible (<em>survey mask</em>, <em>shape noise</em>), the inverse problem is ill-posed <br> <b class="alert">with no unique solution $\kappa$</b></span>

							<div class="fragment">
								<br>
								<br>
								The Bayesian view of the problem:
								<br>
								$$ \boxed{p(\kappa | \gamma) \propto p(\gamma | \kappa) \ p(\kappa)} $$
								
		
								<ul>
									<li class="fragment fade-up">$p(\gamma | \kappa)$ is the data likelihood, which <b>contains the physics</b><br>
									</li>
									<br>
									<li class="fragment fade-up">$p(\kappa)$ is the prior knowledge on the solution.</li>
								</ul>
								<br>
								<br>
							</div>
						</div>
						
						<div class="col">
							<!-- <div class="container"> -->
								<div>
									<!-- Shear <b class="alert">$\gamma$</b><br> -->
									<img data-src="assets/shear_cat1.png" style="width:200px;"></img> <b class="alert">$\gamma$</b>
								</div>
								<div>
									<!-- Convergence <b class="alert">$\kappa$</b><br> -->
									<img data-src="assets/kappa.png" style="width:200px;"></img> <b class="alert">$\kappa$</b>
								</div>
							<!-- </div> -->
						</div>
					</div>


					<div class="fragment">
						In this perspective we can provide point estimates: <b class="alert">Posterior Mean</b>, <b class="alert">Max</b>, <b class="alert">Median</b>, etc. <br>
						and  <b class="alert">the full posterior $p(\kappa|\gamma)$</b> with <b class="alert">Markov Chain Monte Carlo</b> or Variational Inference methods
					</div>

					<br>

					<div class="fragment fade-up">
						<h3>How do you choose the prior ?</h3>
					</div>
				</section>

				<section>
					<h3 class="slide-title"> Classical examples of signal priors </h3>
					<div class="container">
						<div class="col">
							Sparse
							<img data-src="assets/wavelet.png" height="400" class="plain"></img><br>
							$$ \log p(x) = \parallel \mathbf{W} x \parallel_1 $$
						</div>
						<div class="col">
							Gaussian
							<img data-src="assets/zknj8.jpg" height="400" class="plain"></img>
							<b class="alert">$$ \log p(x) = x^t \mathbf{\Sigma^{-1}} x $$</b>
						</div>
						<div class="col">
							Total Variation
							<img data-src="assets/shepp-Logan.ppm" class="plain"></img>
							$$ \log p(x) = \parallel \nabla x \parallel_1 $$

						</div>
					</div>
				</section>

				<!-- <section>
					<h3 class="slide-title"> Illustration on the Dark Energy Survey (DES) Y3</h3>
					Different priors lead to different mass-maps...
					<div style="float:right; font-size: 20px">Jeffrey, et al. (2021)
					</div><br>
					<img data-src="assets/DESY3maps.png" style="height:600px;"></img>
					
				</section> -->

				<section data-background="assets/convergence.png">
					<h2>But what about learning the prior <br>   with <b class="alert">deep generative models</b>?</h2>

					<!-- Maps sampled with these simulations contain also the non-Gaussian statistics
					    because they take into account non linear gravitational collapse and
						baryonic feedback.-->


					<!-- <div class="fragment fade-up">
						<div class="container">
							<div class="col">
								<h2>$\log p(x) =$</h2>
							</div>

						<div class="col">
							<img data-src="assets/nn.png" class="plain"></img>
						</div>

						<br>

					</div>
					
					<br>

					<div class="fragment fade-up">
						Which generative model? GANs, Normalizing Flow, Variational Auto Encoder, Energy Based Model, ...
					</div> -->
					  
				</section>

				<section>
					<h3 class="slide-title"> Our contribution</h3>
					<div align="left">
						We propose to sample the <b class="alert">full posterior distribution</b> $p(\kappa|\gamma)$
					</div>
					<!-- <div style="float:right; font-size: 20px"><b class="alert">HST/ACS COSMOS field</b></div> -->
					<div class="container">
						<div class="col">
							<div class="block-content">
								<div style="position:relative; height:400px; top:0px; left:0px;">
									HST/ACS COSMOS <br>
									Kaiser & Squires (1993)
									<img data-src="assets/ks-cosmos.png" style="height:400px;"></img>
								</div>
							</div>
						</div>

						<div class="col">
							<div class="block-content">
								<div style="position:relative; height:400px; top:0px; left:0px;">
									<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:600px;" data-fragment-index="0">
										HST/ACS COSMOS <br> Remy et al. (2022) <b class="alert">Posterior mean</b>
										<img data-src='assets/remy.png' style="height:400px;" />
									</div>

									<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:600px;" data-fragment-index="1">
										HST/ACS COSMOS <br> Remy et al. (2022) <b class="alert">Posterior samples</b>
										<img data-src='assets/cosmos_samples.gif' style="height:400px;" />
									</div>

									<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:600px;" data-fragment-index="2">
										HST/ACS COSMOS <br> Remy et al. (2022) <b class="alert">Posterior standard deviation</b>
										<img data-src='assets/COSMOS-std.png' style="height:400px;" />
									</div>
								</div>
							</div>
						</div>

					</div>

					<ul>
						<br>
						<br>
						<li>Posterior Mean as a point estimate &#9989;</li>
						<li>Uncertainty Quantifications (posterior samples, moments) &#9989;</li>
						<li><b class="alert">Explicit likelihood</b>: train the network only once, data fidelity garanteed at inference &#9989;</li>
						
					</ul>

				</section>
				
			</section>

			<section>
				<section>
					<h3 class="slide-title">Writing down the convergence map log posterior</h3>
	
	
						$$ \log p( \kappa | e) = \underbrace{\log p(e | \kappa)}_{\simeq -\frac{1}{2} \parallel e - P \kappa \parallel_\Sigma^2} + \log p(\kappa) +cst $$
	
						<ul>
							<li> The likelihood term is <b class="alert">known analytically</b>.
							</li>
	
							<li class="fragment fade-up"> There is <b class="alert">no close form expression for the full non-Gaussian prior</b> of the convergence.
								<br> However:
								<ul>
									<li class='fragment'> <b>We do have access to samples of full  <b class="alert">implicit</b> prior</b> through simulations: $X = \{x_0, x_1, \ldots, x_n \}$ with $x_i \sim \mathbb{P}$
										<br>
										<br>
										<div style="float:right; font-size: 20px"><b class="alert">$\kappa$TNG (Osato et al. 2021)</b>
										</div>
										<img data-src='assets/plot_massive_nu.png' />
									</li>
								</ul>
							</li>
						</ul>
						<div class="fragment">$\Longrightarrow$ Our strategy: <b class="alert">Learn the prior from simulation</b>,
							and then <b class="alert">sample the full posterior</b>.</div>
				</section>

				<!-- <section data-vertical-align-top>
					<h3 class="slide-title">Not all generative models are created equal</h3>
					<img data-src="assets/generative_models_table.png" class="plain"></img>
					<div style="float:right; font-size: 20px">Grathwohl et al. 2018</div>
					<br>
					<br>
					<ul>
						<li> GANs and VAEs are very common and successfull but do not fit our purposes.</li>
						<br>
						<li> We would want a model with <b class="alert">explicit likelihood</b>, which can evaluate $\log p_\theta(x)$.</li>
						<br>
					</ul>
				</section> -->
	
				<section>
					<h3 class="slide-title">The score is all you need!</h3>
					<br>
	
					<div class="container">
						<div class="col">
							<ul>
								<li> Whether you are looking for the MAP or sampling with HMC or MALA, you
									<b class="alert">only need access to the score</b> of the posterior:
									$$\frac{\color{orange} d \color{orange}\log \color{orange}p\color{orange}(\color{orange}x \color{orange}|\color{orange} y\color{orange})}{\color{orange}
									d
									\color{orange}x}$$
									<ul>
										<li>Gradient descent: $x_{t+1} = x_t + \tau \nabla_x \log p(x_t | y) $</li>
										<li>Langevin algorithm: $x_{t+1} = x_t + \tau \nabla_x \log p(x_t | y) + \sqrt{2\tau} n_t$ </li>
									</ul>
								</li>
								<br>
							</ul>
						</div>
						<div class="col">
							<img data-src="assets/score_two_moons.png"></img>
						</div>
					</div>
					<br>
					<br>
					<ul>
						<li class="fragment" data-fragment-index="1"> The score of the full posterior is simply:
							$$\nabla_x \log p(x |y) = \underbrace{\nabla_x \log p(y |x)}_{\mbox{known}} \quad + \quad \underbrace{\nabla_x \log p(x)}_{\mbox{can be learned}}$$
							$\Longrightarrow$ all we have to do is <b class="alert">model/learn the score of the prior</b>.
						</li>
					</ul>
				</section>

				<section>
					<h3 class="slide-title">Neural Score Estimation by Denoising Score Matching</h3>

					<ul>
						<li><b>Denoising Score Matching</b>: An optimal <b class="alert">Gaussian denoiser learns the score</b> of a given distribution.
							<ul>
								<li class="fragment fade-up"> If $x \sim \mathbb{P}$ is corrupted by additional Gaussian noise $u \in \mathcal{N}(0, \sigma^2)$ to yield
									$$x^\prime = x + u$$
								</li>
								<li class="fragment fade-up"> Let's consider a denoiser $r_\theta$ trained under an $\ell_2$ loss:
									$$\mathcal{L}=\parallel x - r_\theta(x^\prime, \sigma) \parallel_2^2$$
								</li>
								<li class="fragment fade-up"> The optimal denoiser $r_{\theta^\star}$ verifies:
									$$\boxed{\boldsymbol{r}_{\theta^\star}(\boldsymbol{x}', \sigma) = \boldsymbol{x}' + \sigma^2 \color{orange}{\nabla_{\boldsymbol{x}} \log p_{\sigma^2}(\boldsymbol{x}')}}$$
								</li>
							</ul>
						</li>
					</ul>

					<div class="fragment fade-up">
						<div class="container">
							
							<div class="col">$\Bigg($
							</div>
							<div class="col">$\boldsymbol{x}'$
								<img data-src="assets/noisy.png"></img>
							</div>
						
							<div class="col">$-$
							</div>
							<div class="col">$\boldsymbol{r}_{\theta^\star}(\boldsymbol{x}', \sigma)$
								<img data-src="assets/denoised-map.png"></img>
							</div>
							<div class="col">$\Bigg)~/~\sigma^2=$
							</div>
							<div class="col">$\color{orange}{\nabla_{\boldsymbol{x}} \log p_{\sigma^2}(\boldsymbol{x}')}$
								<img data-src="assets/score.png"></img>
							</div>
						</div>
						<!-- <img data-src="assets/denoiser-kappa.png" style='width:1200px;'></img> -->
					</div>
				</section>

				<section>
					<h3 class="slide-title">Sampling method: <b class="alert">Annealed Hamiltonian Monte Carlo</b> </h3>
					<div align="left">
						Sampling convergence maps $\kappa \sim p(\kappa|\gamma)$ <b class="alert">is very difficult</b> due to the high dimensionality of the space <br> ( $360 \times 360 \approx 10^{5}$ parameters).
						
						<br>
						<br>
						Especially for MCMC algorithms because of <em>curse of dimensionality</em> leading to <em>highly correlated chains</em>.
					</div>
					<br>

					<div class="fragment">
						We need to design an efficient sampler. $~~~~\kappa_1, \kappa_2, ..., \kappa_N \sim p(\kappa|  \gamma)$
					</div>
					<br>

					<div align="left">
						<ul>
							<!-- <li class="fragment"><b class="alert">Metropolis-Hastings:</b> correction step, acceptance probability (garanties to sample the right posterior distribution)</li> -->
							<br>
							<li class="fragment"><b class="alert">Hamiltonial Monte Carlo</b> proposal for a step size $\alpha$:

							$$\begin{array}{lcl} \boldsymbol{m}_{t+\frac{\alpha}{2}} & = & \boldsymbol{m}_t + \dfrac{\alpha}{2} \color{orange}{\nabla_{\kappa}\log p(\boldsymbol{\kappa}_t|\gamma)} \\ 
							\boldsymbol{\kappa}_{t+\alpha} & = & \boldsymbol{\kappa}_t + \alpha \boldsymbol{\mathrm{M}}^{-1} \boldsymbol{\kappa}_{t+\frac{\alpha}{2}} \\
							\boldsymbol{m}_{t+\alpha} & = & \boldsymbol{m}_{t+\frac{\alpha}{2}} + \dfrac{\alpha}{2} \color{orange}{\nabla_\kappa \log p (\boldsymbol{\kappa}_{t+\alpha}|\gamma)}
							\end{array}$$</li>
							
							<li class="fragment"><b class="alert">Annealing:</b> convolve the posterior with a wide gaussian to always remain on high probability density.
								$$p_\sigma(x) = \int p_{\mathrm{data}}(x')\mathcal{N}(x|x', \sigma^2)dx', ~~~~~~~~\sigma_1 > \sigma_2 > \sigma_3 > \sigma_4 $$
							</li>
							
						</ul>
					</div>
				</section>

				<section>
					<h3 class="slide-title">Sampling method: <b class="alert">Annealed Hamiltonian Monte Carlo</b> </h3>
					<br>
					<!-- <div class="fragment">
						<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:700px;" data-fragment-index="0">
							Initialization $\sigma_T$ is high
							<div>
								<img data-src="assets/annealing_begin.png" />
							</div>
						</div>	
						<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:600px;" data-fragment-index="1">
							
							<div>
								<img data-src="assets/annealing_target.png" />
							</div>
						</div>
					</div> -->
					<div class="block-content">
						<div style="position:relative; height:570px; top:0px; left:0px;">
							<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:1200px;" data-fragment-index="0">
								Target $\sigma_0 \approx 0$
								<img data-src='assets/annealing_target.png' style="width:1100px;" />
							</div>

							<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:1200px;" data-fragment-index="1">
								Initialization $\sigma_T$ is high
								<img data-src='assets/annealing_begin.png' style="width:1100px;" />
							</div>

							<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:1200px;" data-fragment-index="2">
								Annealing scheme
								<img data-src='assets/annealing_scheme.gif' style="width:1100px;" />
							</div>
						</div>
					</div>
				</section>

			</section>

			<section>
				<section>
					<h3 class="slide-title">Illustration on $\kappa$-TNG simulations</h3>
					<div>
						$$\nabla_\kappa \log p_\sigma(\kappa |\gamma) = \nabla_\kappa \log p_\sigma(\gamma |\kappa) \quad + \quad  \color{orange}{\nabla_\kappa \log p_\sigma(\kappa)}$$
						<img data-src='assets/video-annealing.gif'/>
					</div>
				</section>

				<section>
					<h3 class="slide-title">Illustration on $\kappa$-TNG simulations</h3>
					<div class="container">
						<div class="col">
							<img data-src='assets/ref_ktng.png' style="width:400px; height:400px;" />
							<br>
							True convergence map
						</div>
						<div class="col">
							<div class="block-content">
								<div style="position:relative; width:400px; height:400px; top:10px; left:40px;">
									<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="0">
										<img data-src='assets/ks_ktng.png' style="width:400px; height:400px;" />
									</div>
									<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="1">
										<img data-src='assets/wiener_ktng.png' style="width:400px; height:400px;" />
									</div>
									<div class="plain fragment" style="position:absolute;top:0;left:0;width:400px;" data-fragment-index="2">
										<img data-src='assets/mean_post_ktng.png' style="width:400px; height:400px;" />
									</div>
								</div>
								<div class="block-content">
									<div style="position:relative; width:400px; height:20px; top:50px; left:10px;">
										<div class="fragment current-visible " data-fragment-index="0" style="position:absolute;top:0;left:0;width:400px;">Traditional Kaiser-Squires</div>
										<div class="fragment current-visible " data-fragment-index="1" style="position:absolute;top:0;left:0;width:400px;">Wiener Filter</div>
										<div class="fragment" data-fragment-index="2" style="position:absolute;top:0;left:0;width:400px;">Posterior Mean (ours)</div>
									</div>
								</div>
								<br>
								<br>
							</div>

						</div>
						<div class="col fragment">
							<img data-src='assets/cropped.gif' style="width:400px; height:400px;" />
							<br>
							Posterior samples
						</div>
					</div>
				</section>
			</section>	
			
			<section>

				<section>
					<h3 class="slide-title">Reconstruction of the <b class="alert">HST/ACS COSMOS field</b></h3>
					
					1.637 square degree, 64.2 gal/arcmin$^2$
					<br>
					<br>
					<div class="container">
						<div class="col">
							<div class="block-content">
								<div style="position:relative; height:570px; top:0px; left:0px;">
									Massey et al. (2007)
									<img data-src="assets/massey.png" style="height:500px;"></img>
								</div>
							</div>
						</div>

						<div class="col">
							<div class="block-content">
								<div style="position:relative; height:570px; top:0px; left:0px;">
									<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:600px;" data-fragment-index="0">
										Remy et al. (2022) <b class="alert">Posterior mean</b>
										<img data-src='assets/remy.png' style="height:500px;" />
									</div>

									<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:600px;" data-fragment-index="1">
										Remy et al. (2022) <b class="alert">Posterior samples</b>
										<img data-src='assets/cosmos_samples.gif' style="height:500px;" />
									</div>

									<div class="plain fragment current-visible " style="position:absolute;top:0;left:0;width:600px;" data-fragment-index="2">
										Remy et al. (2022)
										<img data-src='assets/COSMOS-std.png' style="height:500px;" />
									</div>
								</div>
							</div>
						</div>

					</div>
				</section>

			</section>

			<section>
				<!-- <section> -->
					<h3 class="slide-title"> Takeaways</h3>
					<br>
					<br>
					<ul>
						<li> Hybrid physical/deep learning modeling:
							<ul>
								<li> Deep generative models can be used to provide <b class="alert">data driven (simulation based) priors</b>.
								</li>
								<br>
								<li> <b class="alert">Explicit likelihood</b>, uses of all of our physical knowledge.<br>
									$\Longrightarrow$ The method can be applied for varying PSF, noise, or even different instruments!
								</li>
	
							</ul>
						</li>
						<br>
						<li>
							Demonstrated the efficiency of annealing Hamiltoninan Monte Carlo for high dimensional posterior sampling.
						</li>
						<br>
						<!-- <li class="fragment"> Neural Score Estimation is a <b class="alert">scalable approach</b> to learn a prior score.
						</li>
						<br>
						<li class="fragment"> Knowledge of the posterior score is all we need for Bayesian inference aka uncertain quantification.
						</li>
						<br> -->
						<li class="fragment">We implemented a new class of mass mapping method, providing the full posterior <br>
		<!-- $\Longrightarrow$ recovered the highest quality convergence map of the COSMOS field to date. -->
		$\Longrightarrow$ Find the highest quality convergence map of the COSMOS field online: <a href=https://zenodo.org/record/5825654>https://zenodo.org/record/5825654</a>
	
							<!-- We implemented the "ultimate mass-mapping method" <br>
							$\Longrightarrow$ Recovered the best convergence map of the COSMOS field to date.</li> -->
					</ul>
					<div class="fragment">
						<a href="https://arxiv.org/abs/2201.05561"><img src="https://img.shields.io/badge/astro--ph.CO-arXiv%3A2201.05561-B31B1B.svg" class="plain" style="height:35px;" /></a>
					</div>
					<br>
					<p class="fragment"> Thank you!</p>
					<br>
					<br>
			
				<!-- </section> -->
			</section>

			<section>
				<section>
					<h3 class="slide-title">Training a Neural Score Estimator in practice</h3>
	
					<div class="container">
						<div class="col">
							<br>
							<img data-src="assets/unet.png" data-fragment-index="1" /><br>
							<br> A standard UNet
						</div>
	
						<div class="col">
							<ul>
								<li> We use a very standard residual UNet, and we adopt a residual
									score matching loss:
									$$ \mathcal{L}_{DSM} = \underset{\boldsymbol{x} \sim P}{\mathbb{E}} \underset{\begin{subarray}{c}
									\boldsymbol{u} \sim \mathcal{N}(0, I) \\
									\sigma_s \sim \mathcal{N}(0, s^2)
									\end{subarray}}{\mathbb{E}} \parallel \boldsymbol{u} + \sigma_s \boldsymbol{r}_{\theta}(\boldsymbol{x} + \sigma_s \boldsymbol{u}, \sigma_s) \parallel_2^2$$
									$\Longrightarrow$ direct estimator of the score $\nabla \log p_\sigma(x)$
								</li>
								<br>
								<li class="fragment fade-up"> Lipschitz regularization to improve robustness:
									<br><br>
									<div class="container">
										<div class="col">
											Without regularization
										</div>
	
										<div class="col">
											With regularization
										</div>
									</div>
									<img data-src='assets/reg_score.png' />
								</li>
							</ul>
						</div>
					</div>
				</section>
	

				<section>
					<h3 class="slide-title">Writing down the convergence map log posterior</h3>
	
	
						$$ \log p( \kappa | e) = \underbrace{\log p(e | \kappa)}_{\simeq -\frac{1}{2} \parallel e - P \kappa \parallel_\Sigma^2} + \color{orange}{\log p(\kappa)} +cst $$
	
						<ul>
							<li> The likelihood term is <b class="alert">known analytically</b>.
							</li>
	
							<li> There is <b class="alert">no close form expression for the full non-Gaussian prior</b> of the convergence.<br>
								
	
								<li class="fragment fade-up"> We learn a <b class="alert">hybrid Denoiser</b>: theoretical Gaussian on large scale, data-driven on small scales using N-body simulations.
								$$\underbrace{\color{orange}{\nabla_{\boldsymbol{\kappa}} \log p(\boldsymbol{\kappa})}}_\text{full prior} = \underbrace{\nabla_{\boldsymbol{\kappa}} \log p_{th}(\boldsymbol{\kappa})}_\text{gaussian prior} +
										\underbrace{\boldsymbol{r}_\theta(\boldsymbol{\kappa}, \nabla_{\boldsymbol{\kappa}} \log p_{th}(\boldsymbol{\kappa}))}_\text{learned residuals}$$
										<center>
										<img data-src='assets/denoiser-kappa.png' style="height:300px; width:auto"/>
										</center>
								<!-- <ul>
									<li class='fragment'> <b>We do have access to samples of full  <b class="alert">implicit</b> prior</b> through simulations: $X = \{x_0, x_1, \ldots, x_n \}$ with $x_i \sim \mathbb{P}$
										<img data-src='assets/plot_massive_nu.png' />
									</li>
								</ul> -->
								</li>
							</li>
						</ul>
				</section>
			</section>

			


		</div>
	</div>

	<style>
		/* .reveal .slides {
			border: 5px solid red;
			min-height: 100%;
			width: 128mm;
			height: 96mm;
		} */

		.reveal .block {
			background-color: #191919;
			margin-left: 20px;
			margin-right: 20px;
			text-align: left;
			padding-bottom: 0.1em;
		}

		.reveal .block-title {
			background-color: #333333;
			padding: 8px 35px 8px 14px;
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .block-content {
			padding: 8px 35px 8px 14px;
		}

		.reveal .slide-title {
			border-left: 5px solid white;
			text-align: left;
			margin-left: 20px;
			padding-left: 20px;
		}

		.reveal .alert {
			color: #FFAA7F;
			font-weight: bold;
		}

		.reveal .inverted {
			filter: invert(100%);
		}

		/*
	/* .reveal .alert {
	padding:8px 35px 8px 14px; margin-bottom:18px;
	text-shadow:0 1px 0 rgba(255,255,255,1);
	border:5px solid #FFAA7F;
	-webkit-border-radius: 14px; -moz-border-radius: 14px;
	border-radius:14px
	background-position: 10px 10px;
	background-repeat: no-repeat;
	background-size: 38px;
	padding-left: 30px; /* 55px; if icon
	}
	.reveal .alert-block {padding-top:14px; padding-bottom:14px}
	.reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
	/*.reveal .alert li {margin-top: 1em}
	.reveal .alert-block p+p {margin-top:5px} */
	</style>


	<script src="reveal.js/dist/reveal.js"></script>
	<script src="reveal.js/plugin/notes/notes.js"></script>
	<script src="reveal.js/plugin/markdown/markdown.js"></script>
	<script src="reveal.js/plugin/highlight/highlight.js"></script>
	<script src="reveal.js/plugin/math/math.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			controls: false,

			//center: false,
			hash: true,

			// Visibility rule for backwards navigation arrows; "faded", "hidden"
			// or "visible"
			controlsBackArrows: 'hidden',

			// Display a presentation progress bar
			progress: true,

			// Display the page number of the current slide
			slideNumber: true,

			transition: 'slide', // none/fade/slide/convex/concave/zoom

			// The "normal" size of the presentation, aspect ratio will be preserved
			// when the presentation is scaled to fit different resolutions. Can be
			// specified using percentage units.
			width: 1280,
			height: 720,

			// Factor of the display size that should remain empty around the content
			margin: 0.1,

			// Bounds for smallest/largest possible scale to apply to content
			minScale: 0.2,
			maxScale: 1.5,


			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath],

			dependencies: [{
					src: 'reveal.js/plugin/markdown/marked.js'
				},
				{
					src: 'reveal.js/plugin/markdown/markdown.js'
				},
				{
					src: 'reveal.js/plugin/notes/notes.js',
					async: true
				},
				{
					src: 'reveal.js/plugin/math/math.js',
					async: true
				},
				{
					src: 'reveal.js/plugin/reveal.js-d3/reveald3.js'
				},
				{
					src: 'reveal.js/plugin/reveal.js-plugins/chart/Chart.min.js'
				},
				{
					src: 'reveal.js/plugin/reveal.js-plugins/chart/csv2chart.js'
				},
				{
					src: 'reveal.js/plugin/highlight/highlight.js',
					async: true
				},
			]

		});
	</script>
</body>

</html>
